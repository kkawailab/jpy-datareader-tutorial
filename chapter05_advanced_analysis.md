# ç¬¬5ç« : ä¸Šç´šç·¨ - ãƒ‡ãƒ¼ã‚¿åˆ†æã®å®Ÿè·µ

## ğŸ“š ã“ã®ç« ã§å­¦ã¶ã“ã¨

- è¤‡æ•°çµ±è¨ˆè¡¨ã®çµåˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
- åœ°åŸŸæ¯”è¼ƒåˆ†æ
- ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®å®Ÿè·µ
- å®Ÿè·µçš„ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¾‹

**å¯¾è±¡ãƒ¬ãƒ™ãƒ«**: ä¸Šç´šè€…
**æ‰€è¦æ™‚é–“**: ç´„90åˆ†
**å‰æçŸ¥è­˜**: ç¬¬1ã€œ4ç« ã®å†…å®¹ã€pandasã€matplotlib/seabornã®åŸºç¤

---

## 5.1 è¤‡æ•°çµ±è¨ˆè¡¨ã®çµåˆ

### 5.1.1 åŸºæœ¬çš„ãªçµåˆ

```python
"""
è¤‡æ•°ã®çµ±è¨ˆè¡¨ã‚’çµåˆã™ã‚‹
"""
import pandas as pd
from jpy_datareader.estat import StatsDataReader
from dotenv import load_dotenv

load_dotenv()

def merge_statistics(stats_id1, stats_id2, merge_keys):
    """
    2ã¤ã®çµ±è¨ˆè¡¨ã‚’çµåˆ

    Parameters:
    -----------
    stats_id1 : str
        çµ±è¨ˆè¡¨ID 1
    stats_id2 : str
        çµ±è¨ˆè¡¨ID 2
    merge_keys : list
        çµåˆã‚­ãƒ¼ã®ãƒªã‚¹ãƒˆ

    Returns:
    --------
    pandas.DataFrame
        çµåˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿
    """
    reader = StatsDataReader()

    # ãƒ‡ãƒ¼ã‚¿1ã‚’å–å¾—
    print(f"çµ±è¨ˆè¡¨1 [{stats_id1}] ã‚’å–å¾—ä¸­...")
    df1 = reader.read(statsDataId=stats_id1, limit=1000)
    print(f"âœ… {len(df1)}ä»¶å–å¾—")

    # ãƒ‡ãƒ¼ã‚¿2ã‚’å–å¾—
    print(f"\nçµ±è¨ˆè¡¨2 [{stats_id2}] ã‚’å–å¾—ä¸­...")
    df2 = reader.read(statsDataId=stats_id2, limit=1000)
    print(f"âœ… {len(df2)}ä»¶å–å¾—")

    # å…±é€šã‚«ãƒ©ãƒ ã‚’ç¢ºèª
    common_cols = set(df1.columns) & set(df2.columns)
    print(f"\nå…±é€šã‚«ãƒ©ãƒ : {len(common_cols)}å€‹")
    print(f"  {', '.join(list(common_cols)[:5])}...")

    # çµåˆ
    print(f"\nçµåˆã‚­ãƒ¼: {merge_keys}")
    df_merged = pd.merge(
        df1, df2,
        on=merge_keys,
        how='inner',  # å†…éƒ¨çµåˆ
        suffixes=('_1', '_2')  # åŒåã‚«ãƒ©ãƒ ã«æ¥å°¾è¾ã‚’ä»˜ã‘ã‚‹
    )

    print(f"âœ… çµåˆå®Œäº†: {len(df_merged)}ä»¶")

    return df_merged


# ä½¿ç”¨ä¾‹ï¼ˆå®Ÿéš›ã®çµ±è¨ˆè¡¨IDã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼‰
# stats_id1 = "0003410379"
# stats_id2 = "0003348423"
# merge_keys = ['åœ°åŸŸã‚³ãƒ¼ãƒ‰', 'æ™‚é–“ã‚³ãƒ¼ãƒ‰']  # å®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«åˆã‚ã›ã‚‹
# df_merged = merge_statistics(stats_id1, stats_id2, merge_keys)
```

---

## 5.2 æ™‚ç³»åˆ—åˆ†æ

### 5.2.1 æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™ã¨å¯è¦–åŒ–

```python
"""
æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ
"""
import pandas as pd
import matplotlib.pyplot as plt
from jpy_datareader.estat import StatsDataReader, MetaInfoReader
from dotenv import load_dotenv

load_dotenv()

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šï¼ˆç’°å¢ƒã«å¿œã˜ã¦èª¿æ•´ï¼‰
plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

class TimeSeriesAnalyzer:
    """
    æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹
    """

    def __init__(self, stats_id):
        """
        åˆæœŸåŒ–

        Parameters:
        -----------
        stats_id : str
            çµ±è¨ˆè¡¨ID
        """
        self.stats_id = stats_id
        self.reader = StatsDataReader()
        self.df = None

    def load_data(self, limit=None):
        """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        print(f"çµ±è¨ˆè¡¨ID {self.stats_id} ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")

        if limit:
            self.df = self.reader.read(statsDataId=self.stats_id, limit=limit)
        else:
            self.df = self.reader.read(statsDataId=self.stats_id)

        print(f"âœ… {len(self.df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

        return self.df

    def prepare_timeseries(self, time_col, value_col, date_format=None):
        """
        æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™

        Parameters:
        -----------
        time_col : str
            æ™‚é–“ã‚«ãƒ©ãƒ å
        value_col : str
            å€¤ã‚«ãƒ©ãƒ å
        date_format : str, optional
            æ—¥ä»˜ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        """
        if self.df is None:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return None

        # æ™‚é–“ã‚«ãƒ©ãƒ ã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®š
        df_ts = self.df[[time_col, value_col]].copy()

        # æ—¥ä»˜å‹ã«å¤‰æ›
        if date_format:
            df_ts[time_col] = pd.to_datetime(df_ts[time_col], format=date_format)
        else:
            df_ts[time_col] = pd.to_datetime(df_ts[time_col], errors='coerce')

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã«è¨­å®š
        df_ts.set_index(time_col, inplace=True)

        # ã‚½ãƒ¼ãƒˆ
        df_ts.sort_index(inplace=True)

        print(f"âœ… æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
        print(f"   æœŸé–“: {df_ts.index.min()} ã€œ {df_ts.index.max()}")
        print(f"   ãƒ‡ãƒ¼ã‚¿æ•°: {len(df_ts)}")

        return df_ts

    def plot_timeseries(self, df_ts, title="Time Series", ylabel="Value"):
        """
        æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆ

        Parameters:
        -----------
        df_ts : pandas.DataFrame
            æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
        title : str
            ã‚°ãƒ©ãƒ•ã‚¿ã‚¤ãƒˆãƒ«
        ylabel : str
            Yè»¸ãƒ©ãƒ™ãƒ«
        """
        plt.figure(figsize=(12, 6))

        plt.plot(df_ts.index, df_ts.iloc[:, 0], marker='o', linestyle='-', linewidth=2)

        plt.title(title, fontsize=16, fontweight='bold')
        plt.xlabel('Date', fontsize=12)
        plt.ylabel(ylabel, fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        plt.tight_layout()

        # ä¿å­˜
        filename = "timeseries_plot.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"âœ… ã‚°ãƒ©ãƒ•ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

        plt.show()

    def calculate_statistics(self, df_ts):
        """
        æ™‚ç³»åˆ—çµ±è¨ˆé‡ã‚’è¨ˆç®—

        Parameters:
        -----------
        df_ts : pandas.DataFrame
            æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
        """
        print("\nã€æ™‚ç³»åˆ—çµ±è¨ˆé‡ã€‘")
        print("=" * 60)

        # åŸºæœ¬çµ±è¨ˆé‡
        print("\nåŸºæœ¬çµ±è¨ˆé‡:")
        print(df_ts.describe())

        # å¤‰åŒ–ç‡ï¼ˆå‰æœŸæ¯”ï¼‰
        pct_change = df_ts.pct_change() * 100
        print(f"\nå¹³å‡å¤‰åŒ–ç‡ï¼ˆå‰æœŸæ¯”ï¼‰: {pct_change.mean().values[0]:.2f}%")
        print(f"æœ€å¤§å¢—åŠ ç‡: {pct_change.max().values[0]:.2f}%")
        print(f"æœ€å¤§æ¸›å°‘ç‡: {pct_change.min().values[0]:.2f}%")

        # ãƒˆãƒ¬ãƒ³ãƒ‰
        trend = (df_ts.iloc[-1] - df_ts.iloc[0]) / df_ts.iloc[0] * 100
        print(f"\nå…¨æœŸé–“ã®ãƒˆãƒ¬ãƒ³ãƒ‰: {trend.values[0]:.2f}%")


# ===== ä½¿ç”¨ä¾‹ =====
# stats_id = "0003410379"
# analyzer = TimeSeriesAnalyzer(stats_id)
# analyzer.load_data(limit=1000)

# å®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«ç½®ãæ›ãˆã¦ãã ã•ã„
# df_ts = analyzer.prepare_timeseries(
#     time_col='æ™‚é–“ã‚³ãƒ¼ãƒ‰',
#     value_col='å€¤'
# )
# analyzer.plot_timeseries(df_ts, title="çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã®æ¨ç§»")
# analyzer.calculate_statistics(df_ts)
```

---

## 5.3 åœ°åŸŸæ¯”è¼ƒåˆ†æ

### 5.3.1 è¤‡æ•°åœ°åŸŸã®æ¯”è¼ƒ

```python
"""
è¤‡æ•°åœ°åŸŸã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¯”è¼ƒåˆ†æ
"""
import pandas as pd
import matplotlib.pyplot as plt
from jpy_datareader.estat import StatsDataReader, MetaInfoReader
from dotenv import load_dotenv

load_dotenv()

class RegionalComparisonAnalyzer:
    """
    åœ°åŸŸæ¯”è¼ƒåˆ†æã‚’è¡Œã†ã‚¯ãƒ©ã‚¹
    """

    def __init__(self, stats_id):
        """åˆæœŸåŒ–"""
        self.stats_id = stats_id
        self.meta_reader = MetaInfoReader()
        self.data_reader = StatsDataReader()
        self.df_meta = None
        self.area_data = {}

    def load_metadata(self):
        """ãƒ¡ã‚¿æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€"""
        self.df_meta = self.meta_reader.read(statsDataId=self.stats_id)
        print(f"âœ… ãƒ¡ã‚¿æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    def get_area_data(self, area_names, limit=1000):
        """
        è¤‡æ•°åœ°åŸŸã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Parameters:
        -----------
        area_names : list
            åœ°åŸŸåã®ãƒªã‚¹ãƒˆ
        limit : int
            å„åœ°åŸŸã®å–å¾—ä»¶æ•°
        """
        if self.df_meta is None:
            self.load_metadata()

        # åœ°åŸŸåˆ†é¡ã‚’æŠ½å‡º
        df_area = self.df_meta[self.df_meta['@class'] == 'area']

        for area_name in area_names:
            print(f"\n{area_name}ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")

            # åœ°åŸŸã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢
            df_found = df_area[df_area['@name'].str.contains(area_name, na=False)]

            if len(df_found) == 0:
                print(f"  âŒ {area_name}ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                continue

            area_code = df_found.iloc[0]['@code']

            # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            df_data = self.data_reader.read(
                statsDataId=self.stats_id,
                cdArea=area_code,
                limit=limit
            )

            self.area_data[area_name] = df_data
            print(f"  âœ… {len(df_data)}ä»¶å–å¾—")

    def compare_statistics(self, value_col):
        """
        åœ°åŸŸé–“ã®çµ±è¨ˆé‡ã‚’æ¯”è¼ƒ

        Parameters:
        -----------
        value_col : str
            æ¯”è¼ƒã™ã‚‹å€¤ã®ã‚«ãƒ©ãƒ å
        """
        print("\nã€åœ°åŸŸæ¯”è¼ƒçµ±è¨ˆé‡ã€‘")
        print("=" * 60)

        comparison = []

        for area_name, df in self.area_data.items():
            if value_col not in df.columns:
                print(f"âš ï¸ {area_name}: ã‚«ãƒ©ãƒ '{value_col}'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue

            stats = {
                'åœ°åŸŸ': area_name,
                'ãƒ‡ãƒ¼ã‚¿æ•°': len(df),
                'å¹³å‡': df[value_col].mean(),
                'ä¸­å¤®å€¤': df[value_col].median(),
                'æœ€å°': df[value_col].min(),
                'æœ€å¤§': df[value_col].max(),
                'æ¨™æº–åå·®': df[value_col].std()
            }

            comparison.append(stats)

        # DataFrameã«å¤‰æ›
        df_comparison = pd.DataFrame(comparison)

        print("\n")
        print(df_comparison.to_string(index=False))

        return df_comparison

    def plot_comparison(self, value_col, plot_type='bar'):
        """
        åœ°åŸŸæ¯”è¼ƒã®ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ

        Parameters:
        -----------
        value_col : str
            ãƒ—ãƒ­ãƒƒãƒˆã™ã‚‹å€¤ã®ã‚«ãƒ©ãƒ å
        plot_type : str
            ã‚°ãƒ©ãƒ•ã®ç¨®é¡ï¼ˆ'bar', 'box', 'line'ï¼‰
        """
        if plot_type == 'bar':
            # æ£’ã‚°ãƒ©ãƒ•
            plt.figure(figsize=(12, 6))

            areas = []
            means = []

            for area_name, df in self.area_data.items():
                if value_col in df.columns:
                    areas.append(area_name)
                    means.append(df[value_col].mean())

            plt.bar(areas, means, color='steelblue', alpha=0.7)
            plt.title('Regional Comparison (Mean Values)', fontsize=16, fontweight='bold')
            plt.xlabel('Region', fontsize=12)
            plt.ylabel(f'Mean {value_col}', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            plt.grid(axis='y', alpha=0.3)
            plt.tight_layout()

            filename = "regional_comparison_bar.png"
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"âœ… ã‚°ãƒ©ãƒ•ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

            plt.show()

        elif plot_type == 'box':
            # ç®±ã²ã’å›³
            plt.figure(figsize=(12, 6))

            data_list = []
            labels = []

            for area_name, df in self.area_data.items():
                if value_col in df.columns:
                    data_list.append(df[value_col].dropna())
                    labels.append(area_name)

            plt.boxplot(data_list, labels=labels)
            plt.title('Regional Comparison (Distribution)', fontsize=16, fontweight='bold')
            plt.xlabel('Region', fontsize=12)
            plt.ylabel(value_col, fontsize=12)
            plt.xticks(rotation=45, ha='right')
            plt.grid(axis='y', alpha=0.3)
            plt.tight_layout()

            filename = "regional_comparison_box.png"
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"âœ… ã‚°ãƒ©ãƒ•ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

            plt.show()


# ===== ä½¿ç”¨ä¾‹ =====
# stats_id = "0003410379"
# analyzer = RegionalComparisonAnalyzer(stats_id)

# åœ°åŸŸãƒªã‚¹ãƒˆ
# regions = ['æ±äº¬éƒ½', 'å¤§é˜ªåºœ', 'åŒ—æµ·é“', 'ç¦å²¡çœŒ']
# analyzer.get_area_data(regions, limit=500)

# æ¯”è¼ƒåˆ†æï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«ç½®ãæ›ãˆï¼‰
# df_comparison = analyzer.compare_statistics(value_col='å€¤')
# analyzer.plot_comparison(value_col='å€¤', plot_type='bar')
```

---

## 5.4 å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: éƒ½é“åºœçœŒåˆ¥äººå£å‹•æ…‹åˆ†æ

### 5.4.1 ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ã‚³ãƒ¼ãƒ‰

```python
"""
å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: éƒ½é“åºœçœŒåˆ¥äººå£å‹•æ…‹åˆ†æ
"""
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from jpy_datareader.estat import StatsDataReader, MetaInfoReader
from dotenv import load_dotenv
import numpy as np

load_dotenv()

class PopulationAnalysisProject:
    """
    äººå£å‹•æ…‹åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
    """

    def __init__(self, stats_id):
        """åˆæœŸåŒ–"""
        self.stats_id = stats_id
        self.meta_reader = MetaInfoReader()
        self.data_reader = StatsDataReader()
        self.df_data = None
        self.df_meta = None

    def step1_load_data(self, limit=None):
        """ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
        print("=" * 60)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ—1ã€‘ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿")
        print("=" * 60)

        # ãƒ¡ã‚¿æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
        self.df_meta = self.meta_reader.read(statsDataId=self.stats_id)
        print(f"âœ… ãƒ¡ã‚¿æƒ…å ±: {len(self.df_meta)}ä»¶")

        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        if limit:
            self.df_data = self.data_reader.read(
                statsDataId=self.stats_id,
                limit=limit
            )
        else:
            self.df_data = self.data_reader.read(statsDataId=self.stats_id)

        print(f"âœ… ãƒ‡ãƒ¼ã‚¿: {len(self.df_data)}ä»¶")
        print(f"   ã‚«ãƒ©ãƒ æ•°: {len(self.df_data.columns)}")

        return self.df_data

    def step2_explore_data(self):
        """ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ç´¢ã™ã‚‹"""
        print("\n" + "=" * 60)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ—2ã€‘ãƒ‡ãƒ¼ã‚¿ã®æ¢ç´¢")
        print("=" * 60)

        # ãƒ‡ãƒ¼ã‚¿å‹ã‚’ç¢ºèª
        print("\nã€ãƒ‡ãƒ¼ã‚¿å‹ã€‘")
        print(self.df_data.dtypes)

        # æ¬ æå€¤ã‚’ç¢ºèª
        print("\nã€æ¬ æå€¤ã€‘")
        missing = self.df_data.isnull().sum()
        missing = missing[missing > 0]
        if len(missing) > 0:
            print(missing)
        else:
            print("æ¬ æå€¤ãªã—")

        # åŸºæœ¬çµ±è¨ˆé‡
        print("\nã€åŸºæœ¬çµ±è¨ˆé‡ã€‘")
        numeric_cols = self.df_data.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            print(self.df_data[numeric_cols].describe())

    def step3_clean_data(self):
        """ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹"""
        print("\n" + "=" * 60)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ—3ã€‘ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°")
        print("=" * 60)

        # å…ƒã®ãƒ‡ãƒ¼ã‚¿ä»¶æ•°
        original_count = len(self.df_data)

        # æ¬ æå€¤ã‚’å‰Šé™¤
        self.df_data = self.df_data.dropna()

        # é‡è¤‡ã‚’å‰Šé™¤
        self.df_data = self.df_data.drop_duplicates()

        cleaned_count = len(self.df_data)
        removed = original_count - cleaned_count

        print(f"å…ƒãƒ‡ãƒ¼ã‚¿: {original_count}ä»¶")
        print(f"å‰Šé™¤: {removed}ä»¶")
        print(f"ã‚¯ãƒªãƒ¼ãƒ³å¾Œ: {cleaned_count}ä»¶")

        return self.df_data

    def step4_analyze(self, group_col, value_col):
        """
        ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã™ã‚‹

        Parameters:
        -----------
        group_col : str
            ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã‚«ãƒ©ãƒ 
        value_col : str
            åˆ†æã™ã‚‹å€¤ã®ã‚«ãƒ©ãƒ 
        """
        print("\n" + "=" * 60)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ—4ã€‘ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ")
        print("=" * 60)

        if group_col not in self.df_data.columns:
            print(f"âŒ ã‚«ãƒ©ãƒ '{group_col}'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None

        if value_col not in self.df_data.columns:
            print(f"âŒ ã‚«ãƒ©ãƒ '{value_col}'ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None

        # ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥é›†è¨ˆ
        df_grouped = self.df_data.groupby(group_col)[value_col].agg([
            ('ä»¶æ•°', 'count'),
            ('åˆè¨ˆ', 'sum'),
            ('å¹³å‡', 'mean'),
            ('ä¸­å¤®å€¤', 'median'),
            ('æœ€å°', 'min'),
            ('æœ€å¤§', 'max'),
            ('æ¨™æº–åå·®', 'std')
        ]).reset_index()

        # ã‚½ãƒ¼ãƒˆï¼ˆå¹³å‡å€¤ã®é™é †ï¼‰
        df_grouped = df_grouped.sort_values('å¹³å‡', ascending=False)

        print(f"\nã€{group_col}åˆ¥ã®çµ±è¨ˆé‡ã€‘")
        print(df_grouped.to_string(index=False))

        return df_grouped

    def step5_visualize(self, df_grouped, group_col, value_col='å¹³å‡'):
        """
        ã‚¹ãƒ†ãƒƒãƒ—5: çµæœã‚’å¯è¦–åŒ–ã™ã‚‹

        Parameters:
        -----------
        df_grouped : pandas.DataFrame
            é›†è¨ˆãƒ‡ãƒ¼ã‚¿
        group_col : str
            ã‚°ãƒ«ãƒ¼ãƒ—ã‚«ãƒ©ãƒ å
        value_col : str
            è¡¨ç¤ºã™ã‚‹å€¤ã®ã‚«ãƒ©ãƒ å
        """
        print("\n" + "=" * 60)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ—5ã€‘ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–")
        print("=" * 60)

        # ä¸Šä½10ä»¶ã®ã¿è¡¨ç¤º
        df_top = df_grouped.head(10)

        # æ£’ã‚°ãƒ©ãƒ•
        plt.figure(figsize=(12, 6))

        plt.bar(range(len(df_top)), df_top[value_col], color='steelblue', alpha=0.7)
        plt.xticks(range(len(df_top)), df_top[group_col], rotation=45, ha='right')
        plt.xlabel(group_col, fontsize=12)
        plt.ylabel(value_col, fontsize=12)
        plt.title(f'Top 10 {group_col} by {value_col}', fontsize=16, fontweight='bold')
        plt.grid(axis='y', alpha=0.3)
        plt.tight_layout()

        filename = "analysis_result.png"
        plt.savefig(filename, dpi=300, bbox_inches='tight')
        print(f"âœ… ã‚°ãƒ©ãƒ•ã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

        plt.show()

    def step6_export(self, df_grouped, filename="analysis_result.csv"):
        """
        ã‚¹ãƒ†ãƒƒãƒ—6: çµæœã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹

        Parameters:
        -----------
        df_grouped : pandas.DataFrame
            é›†è¨ˆãƒ‡ãƒ¼ã‚¿
        filename : str
            å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
        """
        print("\n" + "=" * 60)
        print("ã€ã‚¹ãƒ†ãƒƒãƒ—6ã€‘çµæœã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        print("=" * 60)

        # CSVã«ä¿å­˜
        df_grouped.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"âœ… åˆ†æçµæœã‚’ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")

        # ãƒ¬ãƒãƒ¼ãƒˆã‚‚ä½œæˆ
        report_filename = filename.replace('.csv', '_report.txt')

        with open(report_filename, 'w', encoding='utf-8') as f:
            f.write("=" * 60 + "\n")
            f.write("ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ\n")
            f.write("=" * 60 + "\n\n")
            f.write(f"çµ±è¨ˆè¡¨ID: {self.stats_id}\n")
            f.write(f"ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(self.df_data)}\n")
            f.write(f"ã‚°ãƒ«ãƒ¼ãƒ—æ•°: {len(df_grouped)}\n\n")
            f.write("=" * 60 + "\n")
            f.write("é›†è¨ˆçµæœï¼ˆä¸Šä½10ä»¶ï¼‰\n")
            f.write("=" * 60 + "\n")
            f.write(df_grouped.head(10).to_string(index=False))

        print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆã‚’ {report_filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")


# ===== ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Ÿè¡Œ =====
# stats_id = "0003410379"  # å®Ÿéš›ã®çµ±è¨ˆè¡¨IDã«ç½®ãæ›ãˆ
# project = PopulationAnalysisProject(stats_id)

# ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# project.step1_load_data(limit=5000)

# ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿æ¢ç´¢
# project.step2_explore_data()

# ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# project.step3_clean_data()

# ã‚¹ãƒ†ãƒƒãƒ—4: åˆ†æï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«ç½®ãæ›ãˆï¼‰
# df_result = project.step4_analyze(group_col='åœ°åŸŸå', value_col='å€¤')

# ã‚¹ãƒ†ãƒƒãƒ—5: å¯è¦–åŒ–
# project.step5_visualize(df_result, group_col='åœ°åŸŸå')

# ã‚¹ãƒ†ãƒƒãƒ—6: ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# project.step6_export(df_result)

print("\n" + "=" * 60)
print("ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œäº†ï¼")
print("=" * 60)
```

---

## ğŸ“ ç·´ç¿’å•é¡Œ

### å•é¡Œ1: æ™‚ç³»åˆ—åˆ†æ

**èª²é¡Œ**: ç‰¹å®šã®åœ°åŸŸï¼ˆä¾‹: æ±äº¬éƒ½ï¼‰ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€å‰å¹´æ¯”ã®å¤‰åŒ–ç‡ã‚’è¨ˆç®—ã—ã¦å¯è¦–åŒ–ã—ã¦ãã ã•ã„ã€‚

### å•é¡Œ2: åœ°åŸŸãƒ©ãƒ³ã‚­ãƒ³ã‚°

**èª²é¡Œ**: ã™ã¹ã¦ã®éƒ½é“åºœçœŒã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ç‰¹å®šã®æŒ‡æ¨™ï¼ˆä¾‹: äººå£ï¼‰ã§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚ä¸Šä½10éƒ½é“åºœçœŒã¨ä¸‹ä½10éƒ½é“åºœçœŒã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„ã€‚

### å•é¡Œ3: ç›¸é–¢åˆ†æ

**èª²é¡Œ**: 2ã¤ã®ç•°ãªã‚‹çµ±è¨ˆè¡¨ã‹ã‚‰é–¢é€£ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ç›¸é–¢ä¿‚æ•°ã‚’è¨ˆç®—ã—ã¦ãã ã•ã„ã€‚æ•£å¸ƒå›³ã‚‚ä½œæˆã—ã¦ãã ã•ã„ã€‚

### å•é¡Œ4: åœ°åŸŸã‚°ãƒ«ãƒ¼ãƒ—åˆ†æ

**èª²é¡Œ**: éƒ½é“åºœçœŒã‚’åœ°æ–¹ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆä¾‹: é–¢æ±ã€é–¢è¥¿ãªã©ï¼‰ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®çµ±è¨ˆé‡ã‚’æ¯”è¼ƒã—ã¦ãã ã•ã„ã€‚

### å•é¡Œ5: ç·åˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

**èª²é¡Œ**: ä»¥ä¸‹ã®è¦ä»¶ã‚’æº€ãŸã™åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š
1. è¤‡æ•°å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
2. åœ°åŸŸåˆ¥ãƒ»å¹´åˆ¥ã®é›†è¨ˆ
3. ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
4. å¯è¦–åŒ–ï¼ˆã‚°ãƒ©ãƒ•3ç¨®é¡ä»¥ä¸Šï¼‰
5. ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›

---

## ğŸ“– æ¨¡ç¯„è§£ç­”

### è§£ç­”1: æ™‚ç³»åˆ—åˆ†æ

```python
"""
å•é¡Œ1ã®æ¨¡ç¯„è§£ç­”: æ™‚ç³»åˆ—åˆ†æã¨å‰å¹´æ¯”è¨ˆç®—
"""
import pandas as pd
import matplotlib.pyplot as plt
from jpy_datareader.estat import StatsDataReader, MetaInfoReader
from dotenv import load_dotenv

load_dotenv()

print("ã€æ™‚ç³»åˆ—åˆ†æ: æ±äº¬éƒ½ã®å‰å¹´æ¯”å¤‰åŒ–ã€‘")
print("=" * 60)

stats_id = "0003410379"  # å®Ÿéš›ã®IDã«ç½®ãæ›ãˆ

# ãƒ¡ã‚¿æƒ…å ±ã‹ã‚‰æ±äº¬éƒ½ã®ã‚³ãƒ¼ãƒ‰ã‚’å–å¾—
meta_reader = MetaInfoReader()
df_meta = meta_reader.read(statsDataId=stats_id)

df_area = df_meta[df_meta['@class'] == 'area']
df_tokyo = df_area[df_area['@name'].str.contains('æ±äº¬éƒ½', na=False)]

if len(df_tokyo) > 0:
    tokyo_code = df_tokyo.iloc[0]['@code']
    print(f"âœ… æ±äº¬éƒ½ã‚³ãƒ¼ãƒ‰: {tokyo_code}")

    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    data_reader = StatsDataReader()
    df_data = data_reader.read(
        statsDataId=stats_id,
        cdArea=tokyo_code,
        limit=1000
    )

    print(f"âœ… {len(df_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")

    # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ï¼ˆå®Ÿéš›ã®ã‚«ãƒ©ãƒ åã«ç½®ãæ›ãˆï¼‰
    # df_data['å¹´æœˆ'] = pd.to_datetime(df_data['æ™‚é–“ã‚³ãƒ¼ãƒ‰'])
    # df_data = df_data.sort_values('å¹´æœˆ')

    # å‰å¹´æ¯”ã‚’è¨ˆç®—
    # df_data['å‰å¹´æ¯”'] = df_data['å€¤'].pct_change(12) * 100  # 12ãƒ¶æœˆå‰ã¨ã®æ¯”è¼ƒ

    # å¯è¦–åŒ–
    # fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))

    # å…ƒã®å€¤
    # ax1.plot(df_data['å¹´æœˆ'], df_data['å€¤'], marker='o', linewidth=2)
    # ax1.set_title('Tokyo: Time Series', fontsize=14, fontweight='bold')
    # ax1.set_ylabel('Value', fontsize=12)
    # ax1.grid(True, alpha=0.3)

    # å‰å¹´æ¯”
    # ax2.plot(df_data['å¹´æœˆ'], df_data['å‰å¹´æ¯”'], marker='o', color='red', linewidth=2)
    # ax2.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    # ax2.set_title('Year-over-Year Change Rate', fontsize=14, fontweight='bold')
    # ax2.set_xlabel('Date', fontsize=12)
    # ax2.set_ylabel('Change Rate (%)', fontsize=12)
    # ax2.grid(True, alpha=0.3)

    # plt.tight_layout()
    # plt.savefig('tokyo_timeseries_yoy.png', dpi=300)
    # print("âœ… ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
```

### è§£ç­”2ã€œ5ã¯åŒæ§˜ã®æ§‹é€ ã§å®Ÿè£…ã§ãã¾ã™ã€‚

---

## ğŸ¯ ã¾ã¨ã‚

ã“ã®ç« ã§ã¯ä»¥ä¸‹ã‚’å­¦ã³ã¾ã—ãŸï¼š

âœ… è¤‡æ•°çµ±è¨ˆè¡¨ã®çµåˆãƒ†ã‚¯ãƒ‹ãƒƒã‚¯
âœ… æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®åˆ†ææ‰‹æ³•
âœ… åœ°åŸŸæ¯”è¼ƒåˆ†æã®å®Ÿè·µ
âœ… ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ã®æŠ€è¡“
âœ… å®Ÿè·µçš„ãªåˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æ§‹ç¯‰

---

## ğŸ“š æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

**[ç¬¬6ç« : ä¸Šç´šç·¨ - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹](./chapter06_best_practices.md)**

- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®è©³ç´°
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–
- æœ¬ç•ªç’°å¢ƒã§ã®é‹ç”¨

---

ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼
